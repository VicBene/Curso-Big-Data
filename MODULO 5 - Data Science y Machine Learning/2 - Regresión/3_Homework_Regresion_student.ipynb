{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7-jkWR1LhNMh"},"source":["# Regresión lineal y polinómica: homework\n","\n","\n","\n","------------------------------------------------------\n","\n","\n","### Data Science and Machine Learning\n","\n","#### Febrero 2023\n","\n","**Aurora Cobo Aguilera**\n","\n","**The Valley**\n","\n","------------------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"o3nizph9zK8y"},"source":["# 1. Análisis de la importancia de las características con modelos de regresión lineal\n","\n","Cuando usamos modelos lineales de la forma:\n","\n","$$f(\\mathbf{x}) =  w_0 + w_1 x_1 + w_2 x_2 + \\ldots + w_D x_D, $$\n","\n","cada variable de entrada o característica tiene asociado un peso. ¿El valor de este peso nos indica lo relevante o importante que es cada característica para estimar nuestro *target*? ¿Podríamos usar estos pesos para hacer selección de características?\n","\n","El objetivo de esta primera parte de la práctica es dar respuesta a estas preguntas y para ello vamos a generar un conjunto de datos sintéticos sobre dos escenarios diferentes. De este modo, sabremos a priori qué variables son más relevantes y así podremos analizar los pesos del regresor para ver si su magnitud es acorde con la importancia de las variables."]},{"cell_type":"markdown","metadata":{"id":"b0Sh2l8i1TeN"},"source":["## 1.1. Escenario 1: Variables independientes\n","\n","Para este primer escenario la siguiente celda de código genera un conjunto de datos con 20 variables independientes de las que algunas son relevantes o están relacionas con la variable objetivo mientras que otras son variables ruidosas que no tienen ninguna influencia en la salida. \n","\n","Comience analizando el proceso de generación de datos y luego complete el siguiente ejercicio:"]},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"GyK5YAAn5ftE"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L3GIDQit18Zc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677688151455,"user_tz":-60,"elapsed":1324,"user":{"displayName":"Víctor Beneito López","userId":"18368115777062064849"}},"outputId":"59f42821-9241-4a26-a5b1-d9b6b1cc5b3a"},"source":["np.random.seed(seed=50) # Cambia aquí la semilla aleatoria\n","\n","N = 100\n","D = 20\n","\n","# Genera muestras aleatorias de una distribución Gaussiana\n","X = np.random.randn(N,D) # Media cero y varianza 1\n","\n","# Crea una matriz mezcladora\n","w_relevant = np.array([10, 5, 2, 1, 0.5])\n","w_real = np.concatenate((w_relevant, np.zeros((D-w_relevant.shape[0],)))) # Las últimas variables no tendrán influencia sobre la salida\n","\n","\n","# Obtén las salidas (targets) como una combinación lineal más ruido\n","noise = 0.5 * np.random.randn(N) \n","Y = X @  w_real + noise  # sumarle un ruido\n","\n","\n","print(X.shape)\n","print(Y.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(100, 20)\n","(100,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"HLc_vvX94j5H"},"source":["> **Ejercicio**: Entrene un modelo *Ridge Regression* y un modelo *Lasso*, validando sus parámetros de regularización, y analize los pesos del regresor para cada caso. Tienes el código necesario para el modelo Ridge, repite algo similar para Lasso. Busca el modelo en el librería de sklearn si hace falta.\n"]},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.linear_model import Ridge"],"metadata":{"id":"_OXBD3E66G9-"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d3AczxXk4Pqh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677688156699,"user_tz":-60,"elapsed":417,"user":{"displayName":"Víctor Beneito López","userId":"18368115777062064849"}},"outputId":"645d6691-8eb3-4846-fa0a-65ac2c803635"},"source":["# RIDGE\n","RidgeReg = Ridge() \n","\n","param_grid = {'alpha': np.logspace(-6, 6, 13)}\n","\n","RidgeReg_grid = GridSearchCV(RidgeReg, param_grid, cv=10, scoring='neg_mean_squared_error')\n","RidgeReg_grid.fit(X, Y) \n","\n","print(RidgeReg_grid.best_params_)\n","\n","w_star_RR = RidgeReg_grid.best_estimator_.coef_\n","print(w_star_RR)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'alpha': 1e-06}\n","[ 9.99946959e+00  4.99385994e+00  2.09711793e+00  1.04141301e+00\n","  6.59401184e-01  2.39460018e-02  1.67265404e-02 -1.51216801e-02\n","  4.53815354e-03 -5.89513492e-02  9.64894012e-02 -4.19115920e-02\n"," -1.15513371e-01  2.65243351e-02 -6.34867809e-02  5.99022532e-02\n"," -3.94894601e-02  8.96083905e-02 -3.24214055e-03  4.11749880e-02]\n"]}]},{"cell_type":"code","source":["# LASSO\n","from sklearn.linear_model import Lasso\n","#<SOL>\n","LassoReg = Lasso() \n","\n","param_grid = {'alpha': np.logspace(-6, 6, 13)}\n","\n","LassoReg_grid = GridSearchCV(LassoReg, param_grid, cv=10)\n","LassoReg_grid.fit(X, Y) \n","\n","print(LassoReg_grid.best_params_)\n","\n","w_star_Lasso = LassoReg_grid.best_estimator_.coef_\n","print(w_star_Lasso)\n","#</SOL>"],"metadata":{"id":"iBVh0Su0nqi8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677688159843,"user_tz":-60,"elapsed":627,"user":{"displayName":"Víctor Beneito López","userId":"18368115777062064849"}},"outputId":"a7fd0e75-c4e4-4f7a-88de-d50b4036e250"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'alpha': 0.1}\n","[ 9.83535311  4.91393449  1.94330521  0.97344903  0.52452117  0.\n"," -0.         -0.          0.         -0.          0.         -0.\n"," -0.01868972  0.          0.          0.         -0.          0.\n","  0.          0.        ]\n"]}]},{"cell_type":"markdown","source":[">**Ejercicio**: Añade las gráficas con los w reales y los de las predicciones de Ridge y de Lasso. Para ellos utilizaremos la función *stem* de *matplotlib*. Puedes buscar sobre ella, pero básicamente en una manera de representar secuencias de valores, también conocidos como valores discretos.\n","\n","https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.stem.html\n"],"metadata":{"id":"69y21G_eA629"}},{"cell_type":"code","source":["#<SOL>\n","import matplotlib.pyplot as plt\n","\n","plt.figure()\n","plt.stem(w_real, markerfmt='o', label='Real', use_line_collection=True)\n","plt.stem(w_star_RR, markerfmt='o', label='Ridge Reg', use_line_collection=True)\n","plt.stem(w_star_Lasso, markerfmt='o', label='Lasso', use_line_collection=True)\n","plt.legend()\n","#</SOL>"],"metadata":{"id":"2ZwUAB5JHV98","colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"status":"ok","timestamp":1677688164135,"user_tz":-60,"elapsed":606,"user":{"displayName":"Víctor Beneito López","userId":"18368115777062064849"}},"outputId":"69203bb4-76e7-4bc3-8838-7d32636d11b9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7fb68c4e18b0>"]},"metadata":{},"execution_count":15},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":[">**Ejercicio**: A la vista de la salida, analice los resultados tratando de contestar a estas preguntas:\n","* ¿Los pesos, w,  de los modelos aprendidos nos indican la relevancia de cada variable? Sí\n","* ¿Podríamos usarlos para hacer selección de características? Sí\n","* Si cambiamos la semilla en el generador de datos, ¿los resultados obtenidos son similares? Sí ¿Puede ayudarnos el entrenar diferentes modelos (con diferentes conjuntos de datos generados bajo la misma distribución) para mejorar la selección de características?"],"metadata":{"id":"T4mDmpsy5vYx"}},{"cell_type":"markdown","metadata":{"id":"JtKY_jJ0Bt2c"},"source":["## 1.2. Escenario 2: Variables redundantes\n","\n","Para este segundo escenario vamos a modificar el generador de datos anterior para que en nuestro conjunto de datos haya variables redundantes entre sí. En concreto, vamos a generar 5 réplicas de las variables 1 y 5, y a añadirlas al final de nuestro conjunto de datos. \n","\n","Al igual que antes, comience analizando el proceso de generación de datos y luego complete el ejercicio."]},{"cell_type":"code","metadata":{"id":"mRafuseNCfdj"},"source":["np.random.seed(seed=100) # Cambia aquí la semilla aleatoria\n","\n","N = 100\n","D = 20\n","\n","# Genera muestras aleatorias de una distribución Gaussiana\n","X = np.random.randn(N,D) \n","\n","# Crea una matriz mezcladora\n","w_relevant = np.array([10, 5, 2, 1, 0.5])\n","w_real = np.concatenate((w_relevant, np.zeros((D-w_relevant.shape[0],)))) # Las últimas variables no tendrán influencia sobre la salida\n","\n","# Obtén la salida (target) como una combinación lineal más un ruido\n","noise = 0.5 * np.random.randn(N) \n","Y = X @  w_real + noise\n","\n","# Añadimos repeticiones de algunas variables\n","Num_rep = 5\n","X_1_red = np.tile(X[:,0],(Num_rep,1)).T \n","X_5_red = np.tile(X[:,4],(Num_rep,1)).T  \n","\n","X = np.concatenate((X, X_1_red, X_5_red), axis =1)\n","\n","w_real_all = np.concatenate((w_real, np.tile(w_real[0],Num_rep), np.tile(w_real[4],Num_rep))) \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7HYW95d2JzJM"},"source":["> **Ejercicio**: Entrene nuevamente un modelo *Ridge Regression* y un modelo *Lasso*, validando sus parametros de regularización, y analize los pesos del regresor para cada caso. Vuelva a contestar ahora a las mismas preguntas del ejercicio anterior a la vez que analiza las diferencias."]},{"cell_type":"code","metadata":{"id":"bJ8t_unxCfaH"},"source":["# Incluye aquí tu solución Ridge Regression\n","# <SOL>\n","\n","# </SOL>"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Incluye aquí tu solución LASSO\n","# <SOL>\n","\n","# </SOL>"],"metadata":{"id":"SEeVfY4x6E23"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Incluye aquí tu solución para las gráficas\n","# <SOL>\n","\n","# </SOL>"],"metadata":{"id":"e9nBX0036FNd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nCXU4m2YmB2y"},"source":["## 2. Diseño de modelos y evaluación de prestaciones sobre datos reales\n","\n","En esta segunda parte vamos a resolver el problema de *California Housing* usando todas sus variables de entrada y usando un modelo de regresión polinómico regularizado. Para ello consideraremos un modelo *Ridge Regression* y un modelo *Lasso* y compararemos y analizaremos sus resultados. \n","\n","Para resolver este apartado tendrás que seguir los siguientes  pasos. Algunos ya están resueltos:\n","* 1. Carga y preprocesado de la base de datos: carga de datos, división en particiones de entrenamiento y test (40\\% train y 60\\% test) y normalización.\n","\n"]},{"cell_type":"code","source":["from sklearn.datasets import fetch_california_housing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import PolynomialFeatures\n","from warnings import filterwarnings\n","\n","filterwarnings('ignore')"],"metadata":{"id":"d4gB05gvYynV"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-7fqumVhhJAl"},"source":["## 1. Cargar y preprocesar el dataset\n","\n","# Carga y analiza los datos\n","housing = fetch_california_housing()\n","X = housing.data\n","Y = housing.target\n","feature_names = housing.feature_names\n","\n","# Genera los subconjuntos de entrenamiento y test\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.6, random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(feature_names)\n","print(X_train.shape)"],"metadata":{"id":"e-4n5ylTZsS9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","**Ejercicio**:\n","\n","2. Entrenamiento y validación del modelo de regresión con variables polinómicas. Aquí tenga en cuenta que, tanto para el modelo *Ridge Regression* como para *Lasso*, deberá validar conjuntamente el grado del polinomio y el parametro de regularización del regresor. Para hacer esta validación conjunta se recomienda definir el modelo con un **pipeline** y validar el grado del polinomio en el rango $\\{1, 2, 3, 4\\}$ y el parámetro de regularización en $\\{10^{-6}, 10^{-4}, 0.01, 1, 100\\}$. Tenga en cuenta que utilizando 8 variables de entrada, la extensión polinómica no puede utilizar un grado muy alto para evitar sobredimensionar el nuevo conjunto de datos (lo que nos podría llevar a problemas de memoria, cómputo, ...)."],"metadata":{"id":"i4nq6B9c-Uto"}},{"cell_type":"code","metadata":{"id":"EnOY0K4Fo62S"},"source":["## 2. Entrenamiento del modelo y validación de los parámetros\n","\n","# Definimos el pipeline con sus pasos para cada modelo. Este código es útil para reutilizar en el futuro\n","PolyRidgeReg_pipeline = Pipeline(steps=[('Poly', PolynomialFeatures(include_bias=False)), ('Norm', StandardScaler()), ('Reg', Ridge(fit_intercept='True'))])\n","PolyLasso_pipeline = Pipeline(steps=[('Poly', PolynomialFeatures(include_bias=False)), ('Norm', StandardScaler()), ('Reg', Lasso(fit_intercept='True'))])\n","\n","# Definimos los parametros a CV (cada parámetro se asocia con su paso: Poly __ degree)\n","param_grid = {'Poly__degree': # </SOL>, 'Reg__alpha': # </SOL>}\n","\n","# Creamos el grid search y validamos el grado del polinonio con fit para cada modelo\n","PolyRidgeReg_grid = GridSearchCV(# </SOL>\n","PolyRidgeReg_grid.fit(# </SOL>\n","\n","PolyLasso_grid = # </SOL>\n","PolyLasso_grid.fit(# </SOL>\n","\n","# Vemos el parámetro seleccionado por CV\n","print('Result of CV in RR:')\n","print(PolyRidgeReg_grid.best_params_)\n","print('Result of CV in LASSO:')\n","print(PolyLasso_grid.best_params_)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Ejercicio**:\n","3. Evaluación del modelo sobre el conjunto de test y análisis de resultados. Mida el MSE sobre el conjunto de test y analice los modelos obtenidos.  Muestre también los coeficientes, w, obtenidos."],"metadata":{"id":"GhSVzFSy-ey7"}},{"cell_type":"code","metadata":{"id":"jtDSa1iq-G9V"},"source":["## 3. Evaluación del rendimiento \n","# Evaluamos los modelos sobre el conjunto de test\n","# Incluye tu código aquí. Añade tantas celdas como sea necesario\n","\n","#<SOL>\n","\n","\n","\n","print('Pesos de Ridge:')\n","print(PolyRidgeReg_grid.best_estimator_.steps[2][1].coef_)\n","\n","\n","\n","\n","\n","\n","#<\\SOL>"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Ejercicio**:\n","4. Compare las prestaciones de estos modelos con las de otros modelos de regresión que ya ha visto en clase como K-NN. Muestre el número de vecinos validado y el MSE. ¿Por qué cree que estos modelos obtienen mejores prestaciones? ¿Podríamos llegar a prestaciones similares con el modelo de regresión polinómica si incluimos lo que hemos aprendido a lo largo del notebook sobre el problema?"],"metadata":{"id":"ynGPzfea-_RJ"}},{"cell_type":"code","metadata":{"id":"uSVJSIcpzVzL"},"source":["## 4. KNN\n","# Incluye tu código aquí. Añade tantas celdas como sea necesario\n","\n"],"execution_count":null,"outputs":[]}]}